{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: string (nullable = true)\n",
      " |-- ast: string (nullable = true)\n",
      " |-- blk: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- drb: string (nullable = true)\n",
      " |-- fg: string (nullable = true)\n",
      " |-- fg3: string (nullable = true)\n",
      " |-- fg3_pct: string (nullable = true)\n",
      " |-- fg3a: string (nullable = true)\n",
      " |-- fg_pct: string (nullable = true)\n",
      " |-- fga: string (nullable = true)\n",
      " |-- ft: string (nullable = true)\n",
      " |-- ft_pct: string (nullable = true)\n",
      " |-- fta: string (nullable = true)\n",
      " |-- game_location: string (nullable = true)\n",
      " |-- game_result: string (nullable = true)\n",
      " |-- game_score: string (nullable = true)\n",
      " |-- gs: string (nullable = true)\n",
      " |-- mp: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- opp_id: string (nullable = true)\n",
      " |-- orb: string (nullable = true)\n",
      " |-- pf: string (nullable = true)\n",
      " |-- pts: string (nullable = true)\n",
      " |-- stl: string (nullable = true)\n",
      " |-- tm: string (nullable = true)\n",
      " |-- tov: string (nullable = true)\n",
      " |-- trb: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "\n",
    "# A JSON dataset is pointed to by path.\n",
    "# The path can be either a single text file or a directory storing text files\n",
    "path = \"items.json\"\n",
    "df = spark.read.json(path)\n",
    "\n",
    "# The inferred schema can be visualized using the printSchema() method\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age='26-133', ast='0', blk='0', date='1994-11-04', drb='0', fg='0', fg3='0', fg3_pct=None, fg3a='0', fg_pct=None, fga='0', ft='0', ft_pct=None, fta='0', game_location=None, game_result='W (+18)', game_score='0.9', gs='0', mp='3:00', name='Alaa_Abdelnaby', opp_id='PHO', orb='1', pf='2', pts='0', stl='1', tm='SAC', tov='0', trb='1')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DateType\n",
    "func =  udf (lambda x: datetime.strptime(x, '%Y-%m-%d'), DateType())\n",
    "\n",
    "df = df.withColumn('date', func(col('date')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age='26-133', ast='0', blk='0', date=datetime.date(1994, 11, 4), drb='0', fg='0', fg3='0', fg3_pct=None, fg3a='0', fg_pct=None, fga='0', ft='0', ft_pct=None, fta='0', game_location=None, game_result='W (+18)', game_score='0.9', gs='0', mp='3:00', name='Alaa_Abdelnaby', opp_id='PHO', orb='1', pf='2', pts='0', stl='1', tm='SAC', tov='0', trb='1')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = (\"2018-08-01\")\n",
    "date_from = [to_date(lit(s)).cast(TimestampType()) for s in dates]\n",
    "\n",
    "df2 = df.filter(col(\"date\") > unix_timestamp(lit('2018-09-01 00:00:00')).cast('timestamp'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age='25-076', ast='0', blk='0', date=datetime.date(2018, 10, 16), drb='2', fg='3', fg3='2', fg3_pct='.333', fg3a='6', fg_pct='.375', fga='8', ft='0', ft_pct=None, fta='0', game_location='@', game_result='L (-8)', game_score='3.4', gs='0', mp='23:28', name='√Ålex_Abrines', opp_id='GSW', orb='0', pf='2', pts='8', stl='0', tm='OKC', tov='0', trb='2')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.write.csv('games2018+.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.toPandas().to_csv('games2018+.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
